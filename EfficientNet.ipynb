{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92985e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86842ce3",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "https://deep-learning-study.tistory.com/563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "475aad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filen_name</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train0001.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train0002.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train0003.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train0004.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train0005.png</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>train4996.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>train4997.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>train4998.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>train4999.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>train5000.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filen_name  label\n",
       "0     train0001.png      8\n",
       "1     train0002.png      8\n",
       "2     train0003.png      8\n",
       "3     train0004.png      8\n",
       "4     train0005.png      8\n",
       "...             ...    ...\n",
       "4995  train4996.png      6\n",
       "4996  train4997.png      6\n",
       "4997  train4998.png      6\n",
       "4998  train4999.png      6\n",
       "4999  train5000.png      6\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './train/train_data.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27b89505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_file_name = df['filen_name']\n",
    "train_label = df['label']\n",
    "\n",
    "# image 파일을 불러온뒤 변수에 저장\n",
    "train_image = []\n",
    "for file in train_file_name:\n",
    "    train_image.append(Image.open('./train/' + file))\n",
    "image_to_number = np.array([np.array(image).flatten() for image in train_image])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7398b6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = pd.DataFrame(image_to_number)\n",
    "all_images['labels'] = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6f94cbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "class MNIST(Dataset):\n",
    "    \n",
    "    def __init__(self, file_path_list, labels = None):\n",
    "        self.file_path_list = file_path_list\n",
    "        self.labels = labels\n",
    "        self.PIL2tensor = transforms.PILToTensor()\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = Image.open(self.file_path_list[idx]) # 해당 인덱스에 맞는 image 추출\n",
    "        image = np.stack((image,) *3,axis=-1)\n",
    "        image = Image.fromarray(image)\n",
    "        tensor_image = self.PIL2tensor(image) # PIL로 읽은 이미지를 torch tensor형으로 변환\n",
    "        flattened_image = tensor_image.float() # 2차원 이미지를 1차원으로 변환\n",
    "        \n",
    "        if self.labels is not  None: # 라벨이 존재 하는경우 : 학습에 이용할경우\n",
    "            label = self.labels[idx] # 해당 인덱스에 맞는 라벨 추출\n",
    "            return flattened_image, label # 1차원으로 변환한 이미지와 라벨을 return\n",
    "        \n",
    "        return flattened_image # test 단계에선 label이 존재하지 않기 때문에 image만을 return\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3c00882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_path_list  = './train/' + df['filen_name']\n",
    "labels = df['label']\n",
    "\n",
    "mnist_dataset = MNIST(file_path_list, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3564b801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3a521bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_loader = DataLoader(mnist_dataset, batch_size = 32, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "88d533a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size :  torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "class Swish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(1,1,28,28)\n",
    "    model = Swish()\n",
    "    output = model(x)\n",
    "    print('output size : ',output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c66bae57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size :  torch.Size([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self,in_channels, r=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels * r),\n",
    "            Swish(),\n",
    "            nn.Linear(in_channels * r, in_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.squeeze(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.excitation(x)\n",
    "        x = x.view(x.size(0),x.size(1),1,1)\n",
    "        return x\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(1,1,28,28)\n",
    "    model = SEBlock(x.size(1))\n",
    "    output = model(x)\n",
    "    print('output size : ',output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15176b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([3, 16, 24, 24]) Stochastic depth: tensor(False)\n"
     ]
    }
   ],
   "source": [
    "class MBConv(nn.Module):\n",
    "    expand = 6\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first MBConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels * MBConv.expand, 1, stride=stride, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_channels * MBConv.expand, in_channels * MBConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*MBConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * MBConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * MBConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*MBConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 16, 24, 24)\n",
    "    model = MBConv(x.size(1), x.size(1), 3, stride=1, p=1)\n",
    "    model.train()\n",
    "    output = model(x)\n",
    "    x = (output == x)\n",
    "    print('output size:', output.size(), 'Stochastic depth:', x[1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "005d403e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([3, 16, 24, 24]) Stochastic depth: tensor(False)\n"
     ]
    }
   ],
   "source": [
    "class SepConv(nn.Module):\n",
    "    expand = 1\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, se_scale=4, p=0.5):\n",
    "        super().__init__()\n",
    "        # first SepConv is not using stochastic depth\n",
    "        self.p = torch.tensor(p).float() if (in_channels == out_channels) else torch.tensor(1).float()\n",
    "\n",
    "        self.residual = nn.Sequential(\n",
    "            nn.Conv2d(in_channels * SepConv.expand, in_channels * SepConv.expand, kernel_size=kernel_size,\n",
    "                      stride=1, padding=kernel_size//2, bias=False, groups=in_channels*SepConv.expand),\n",
    "            nn.BatchNorm2d(in_channels * SepConv.expand, momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        )\n",
    "\n",
    "        self.se = SEBlock(in_channels * SepConv.expand, se_scale)\n",
    "\n",
    "        self.project = nn.Sequential(\n",
    "            nn.Conv2d(in_channels*SepConv.expand, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels, momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.shortcut = (stride == 1) and (in_channels == out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # stochastic depth\n",
    "        if self.training:\n",
    "            if not torch.bernoulli(self.p):\n",
    "                return x\n",
    "\n",
    "        x_shortcut = x\n",
    "        x_residual = self.residual(x)\n",
    "        x_se = self.se(x_residual)\n",
    "\n",
    "        x = x_se * x_residual\n",
    "        x = self.project(x)\n",
    "\n",
    "        if self.shortcut:\n",
    "            x= x_shortcut + x\n",
    "\n",
    "        return x\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 16, 24, 24)\n",
    "    model = SepConv(x.size(1), x.size(1), 3, stride=1, p=1)\n",
    "    model.train()\n",
    "    output = model(x)\n",
    "    # stochastic depth check\n",
    "    x = (output == x)\n",
    "    print('output size:', output.size(), 'Stochastic depth:', x[1,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "19d49407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: torch.Size([3, 10])\n"
     ]
    }
   ],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, width_coef=1., depth_coef=1., scale=1., dropout=0.2, se_scale=4, stochastic_depth=False, p=0.5):\n",
    "        super().__init__()\n",
    "        channels = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "        repeats = [1, 2, 2, 3, 3, 4, 1]\n",
    "        strides = [1, 2, 2, 2, 1, 2, 1]\n",
    "        kernel_size = [3, 3, 5, 3, 5, 5, 3]\n",
    "        depth = depth_coef\n",
    "        width = width_coef\n",
    "\n",
    "        channels = [int(x*width) for x in channels]\n",
    "        repeats = [int(x*depth) for x in repeats]\n",
    "\n",
    "        # stochastic depth\n",
    "        if stochastic_depth:\n",
    "            self.p = p\n",
    "            self.step = (1 - 0.5) / (sum(repeats) - 1)\n",
    "        else:\n",
    "            self.p = 1\n",
    "            self.step = 0\n",
    "\n",
    "\n",
    "        # efficient net\n",
    "        self.upsample = nn.Upsample(scale_factor=scale, mode='bilinear', align_corners=False)\n",
    "\n",
    "        self.stage1 = nn.Sequential(\n",
    "            nn.Conv2d(3, channels[0],3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[0], momentum=0.99, eps=1e-3)\n",
    "        )\n",
    "\n",
    "        self.stage2 = self._make_Block(SepConv, repeats[0], channels[0], channels[1], kernel_size[0], strides[0], se_scale)\n",
    "\n",
    "        self.stage3 = self._make_Block(MBConv, repeats[1], channels[1], channels[2], kernel_size[1], strides[1], se_scale)\n",
    "\n",
    "        self.stage4 = self._make_Block(MBConv, repeats[2], channels[2], channels[3], kernel_size[2], strides[2], se_scale)\n",
    "\n",
    "        self.stage5 = self._make_Block(MBConv, repeats[3], channels[3], channels[4], kernel_size[3], strides[3], se_scale)\n",
    "\n",
    "        self.stage6 = self._make_Block(MBConv, repeats[4], channels[4], channels[5], kernel_size[4], strides[4], se_scale)\n",
    "\n",
    "        self.stage7 = self._make_Block(MBConv, repeats[5], channels[5], channels[6], kernel_size[5], strides[5], se_scale)\n",
    "\n",
    "        self.stage8 = self._make_Block(MBConv, repeats[6], channels[6], channels[7], kernel_size[6], strides[6], se_scale)\n",
    "\n",
    "        self.stage9 = nn.Sequential(\n",
    "            nn.Conv2d(channels[7], channels[8], 1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(channels[8], momentum=0.99, eps=1e-3),\n",
    "            Swish()\n",
    "        ) \n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.linear = nn.Linear(channels[8], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.upsample(x)\n",
    "        x = self.stage1(x)\n",
    "        x = self.stage2(x)\n",
    "        x = self.stage3(x)\n",
    "        x = self.stage4(x)\n",
    "        x = self.stage5(x)\n",
    "        x = self.stage6(x)\n",
    "        x = self.stage7(x)\n",
    "        x = self.stage8(x)\n",
    "        x = self.stage9(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "    def _make_Block(self, block, repeats, in_channels, out_channels, kernel_size, stride, se_scale):\n",
    "        strides = [stride] + [1] * (repeats - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(in_channels, out_channels, kernel_size, stride, se_scale, self.p))\n",
    "            in_channels = out_channels\n",
    "            self.p -= self.step\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def efficientnet_b0(num_classes=10):\n",
    "    return EfficientNet( width_coef=1.0, depth_coef=1.0, scale=1.0,dropout=0.2, se_scale=4)\n",
    "\n",
    "def efficientnet_b1(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.0, depth_coef=1.1, scale=240/224, dropout=0.2, se_scale=4)\n",
    "\n",
    "def efficientnet_b2(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.1, depth_coef=1.2, scale=260/224., dropout=0.3, se_scale=4)\n",
    "\n",
    "def efficientnet_b3(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.2, depth_coef=1.4, scale=300/224, dropout=0.3, se_scale=4)\n",
    "\n",
    "def efficientnet_b4(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.4, depth_coef=1.8, scale=380/224, dropout=0.4, se_scale=4)\n",
    "\n",
    "def efficientnet_b5(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.6, depth_coef=2.2, scale=456/224, dropout=0.4, se_scale=4)\n",
    "\n",
    "def efficientnet_b6(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=1.8, depth_coef=2.6, scale=528/224, dropout=0.5, se_scale=4)\n",
    "\n",
    "def efficientnet_b7(num_classes=10):\n",
    "    return EfficientNet(num_classes=num_classes, width_coef=2.0, depth_coef=3.1, scale=600/224, dropout=0.5, se_scale=4)\n",
    "\n",
    "\n",
    "# check\n",
    "if __name__ == '__main__':\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    x = torch.randn(3, 3, 224, 224).to(device)\n",
    "    model = efficientnet_b0().to(device)\n",
    "    output = model(x)\n",
    "    print('output size:', output.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4a3efda1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "          Upsample-1            [-1, 3, 28, 28]               0\n",
      "            Conv2d-2           [-1, 32, 14, 14]             864\n",
      "       BatchNorm2d-3           [-1, 32, 14, 14]              64\n",
      "            Conv2d-4           [-1, 32, 14, 14]             288\n",
      "       BatchNorm2d-5           [-1, 32, 14, 14]              64\n",
      "           Sigmoid-6           [-1, 32, 14, 14]               0\n",
      "             Swish-7           [-1, 32, 14, 14]               0\n",
      " AdaptiveAvgPool2d-8             [-1, 32, 1, 1]               0\n",
      "            Linear-9                  [-1, 128]           4,224\n",
      "          Sigmoid-10                  [-1, 128]               0\n",
      "            Swish-11                  [-1, 128]               0\n",
      "           Linear-12                   [-1, 32]           4,128\n",
      "          Sigmoid-13                   [-1, 32]               0\n",
      "          SEBlock-14             [-1, 32, 1, 1]               0\n",
      "           Conv2d-15           [-1, 16, 14, 14]             512\n",
      "      BatchNorm2d-16           [-1, 16, 14, 14]              32\n",
      "          SepConv-17           [-1, 16, 14, 14]               0\n",
      "           Conv2d-18             [-1, 96, 7, 7]           1,536\n",
      "      BatchNorm2d-19             [-1, 96, 7, 7]             192\n",
      "          Sigmoid-20             [-1, 96, 7, 7]               0\n",
      "            Swish-21             [-1, 96, 7, 7]               0\n",
      "           Conv2d-22             [-1, 96, 7, 7]             864\n",
      "      BatchNorm2d-23             [-1, 96, 7, 7]             192\n",
      "          Sigmoid-24             [-1, 96, 7, 7]               0\n",
      "            Swish-25             [-1, 96, 7, 7]               0\n",
      "AdaptiveAvgPool2d-26             [-1, 96, 1, 1]               0\n",
      "           Linear-27                  [-1, 384]          37,248\n",
      "          Sigmoid-28                  [-1, 384]               0\n",
      "            Swish-29                  [-1, 384]               0\n",
      "           Linear-30                   [-1, 96]          36,960\n",
      "          Sigmoid-31                   [-1, 96]               0\n",
      "          SEBlock-32             [-1, 96, 1, 1]               0\n",
      "           Conv2d-33             [-1, 24, 7, 7]           2,304\n",
      "      BatchNorm2d-34             [-1, 24, 7, 7]              48\n",
      "           MBConv-35             [-1, 24, 7, 7]               0\n",
      "           Conv2d-36            [-1, 144, 7, 7]           3,456\n",
      "      BatchNorm2d-37            [-1, 144, 7, 7]             288\n",
      "          Sigmoid-38            [-1, 144, 7, 7]               0\n",
      "            Swish-39            [-1, 144, 7, 7]               0\n",
      "           Conv2d-40            [-1, 144, 7, 7]           1,296\n",
      "      BatchNorm2d-41            [-1, 144, 7, 7]             288\n",
      "          Sigmoid-42            [-1, 144, 7, 7]               0\n",
      "            Swish-43            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-44            [-1, 144, 1, 1]               0\n",
      "           Linear-45                  [-1, 576]          83,520\n",
      "          Sigmoid-46                  [-1, 576]               0\n",
      "            Swish-47                  [-1, 576]               0\n",
      "           Linear-48                  [-1, 144]          83,088\n",
      "          Sigmoid-49                  [-1, 144]               0\n",
      "          SEBlock-50            [-1, 144, 1, 1]               0\n",
      "           Conv2d-51             [-1, 24, 7, 7]           3,456\n",
      "      BatchNorm2d-52             [-1, 24, 7, 7]              48\n",
      "           MBConv-53             [-1, 24, 7, 7]               0\n",
      "           Conv2d-54            [-1, 144, 4, 4]           3,456\n",
      "      BatchNorm2d-55            [-1, 144, 4, 4]             288\n",
      "          Sigmoid-56            [-1, 144, 4, 4]               0\n",
      "            Swish-57            [-1, 144, 4, 4]               0\n",
      "           Conv2d-58            [-1, 144, 4, 4]           3,600\n",
      "      BatchNorm2d-59            [-1, 144, 4, 4]             288\n",
      "          Sigmoid-60            [-1, 144, 4, 4]               0\n",
      "            Swish-61            [-1, 144, 4, 4]               0\n",
      "AdaptiveAvgPool2d-62            [-1, 144, 1, 1]               0\n",
      "           Linear-63                  [-1, 576]          83,520\n",
      "          Sigmoid-64                  [-1, 576]               0\n",
      "            Swish-65                  [-1, 576]               0\n",
      "           Linear-66                  [-1, 144]          83,088\n",
      "          Sigmoid-67                  [-1, 144]               0\n",
      "          SEBlock-68            [-1, 144, 1, 1]               0\n",
      "           Conv2d-69             [-1, 40, 4, 4]           5,760\n",
      "      BatchNorm2d-70             [-1, 40, 4, 4]              80\n",
      "           MBConv-71             [-1, 40, 4, 4]               0\n",
      "           Conv2d-72            [-1, 240, 4, 4]           9,600\n",
      "      BatchNorm2d-73            [-1, 240, 4, 4]             480\n",
      "          Sigmoid-74            [-1, 240, 4, 4]               0\n",
      "            Swish-75            [-1, 240, 4, 4]               0\n",
      "           Conv2d-76            [-1, 240, 4, 4]           6,000\n",
      "      BatchNorm2d-77            [-1, 240, 4, 4]             480\n",
      "          Sigmoid-78            [-1, 240, 4, 4]               0\n",
      "            Swish-79            [-1, 240, 4, 4]               0\n",
      "AdaptiveAvgPool2d-80            [-1, 240, 1, 1]               0\n",
      "           Linear-81                  [-1, 960]         231,360\n",
      "          Sigmoid-82                  [-1, 960]               0\n",
      "            Swish-83                  [-1, 960]               0\n",
      "           Linear-84                  [-1, 240]         230,640\n",
      "          Sigmoid-85                  [-1, 240]               0\n",
      "          SEBlock-86            [-1, 240, 1, 1]               0\n",
      "           Conv2d-87             [-1, 40, 4, 4]           9,600\n",
      "      BatchNorm2d-88             [-1, 40, 4, 4]              80\n",
      "           MBConv-89             [-1, 40, 4, 4]               0\n",
      "           Conv2d-90            [-1, 240, 2, 2]           9,600\n",
      "      BatchNorm2d-91            [-1, 240, 2, 2]             480\n",
      "          Sigmoid-92            [-1, 240, 2, 2]               0\n",
      "            Swish-93            [-1, 240, 2, 2]               0\n",
      "           Conv2d-94            [-1, 240, 2, 2]           2,160\n",
      "      BatchNorm2d-95            [-1, 240, 2, 2]             480\n",
      "          Sigmoid-96            [-1, 240, 2, 2]               0\n",
      "            Swish-97            [-1, 240, 2, 2]               0\n",
      "AdaptiveAvgPool2d-98            [-1, 240, 1, 1]               0\n",
      "           Linear-99                  [-1, 960]         231,360\n",
      "         Sigmoid-100                  [-1, 960]               0\n",
      "           Swish-101                  [-1, 960]               0\n",
      "          Linear-102                  [-1, 240]         230,640\n",
      "         Sigmoid-103                  [-1, 240]               0\n",
      "         SEBlock-104            [-1, 240, 1, 1]               0\n",
      "          Conv2d-105             [-1, 80, 2, 2]          19,200\n",
      "     BatchNorm2d-106             [-1, 80, 2, 2]             160\n",
      "          MBConv-107             [-1, 80, 2, 2]               0\n",
      "          Conv2d-108            [-1, 480, 2, 2]          38,400\n",
      "     BatchNorm2d-109            [-1, 480, 2, 2]             960\n",
      "         Sigmoid-110            [-1, 480, 2, 2]               0\n",
      "           Swish-111            [-1, 480, 2, 2]               0\n",
      "          Conv2d-112            [-1, 480, 2, 2]           4,320\n",
      "     BatchNorm2d-113            [-1, 480, 2, 2]             960\n",
      "         Sigmoid-114            [-1, 480, 2, 2]               0\n",
      "           Swish-115            [-1, 480, 2, 2]               0\n",
      "AdaptiveAvgPool2d-116            [-1, 480, 1, 1]               0\n",
      "          Linear-117                 [-1, 1920]         923,520\n",
      "         Sigmoid-118                 [-1, 1920]               0\n",
      "           Swish-119                 [-1, 1920]               0\n",
      "          Linear-120                  [-1, 480]         922,080\n",
      "         Sigmoid-121                  [-1, 480]               0\n",
      "         SEBlock-122            [-1, 480, 1, 1]               0\n",
      "          Conv2d-123             [-1, 80, 2, 2]          38,400\n",
      "     BatchNorm2d-124             [-1, 80, 2, 2]             160\n",
      "          MBConv-125             [-1, 80, 2, 2]               0\n",
      "          Conv2d-126            [-1, 480, 2, 2]          38,400\n",
      "     BatchNorm2d-127            [-1, 480, 2, 2]             960\n",
      "         Sigmoid-128            [-1, 480, 2, 2]               0\n",
      "           Swish-129            [-1, 480, 2, 2]               0\n",
      "          Conv2d-130            [-1, 480, 2, 2]           4,320\n",
      "     BatchNorm2d-131            [-1, 480, 2, 2]             960\n",
      "         Sigmoid-132            [-1, 480, 2, 2]               0\n",
      "           Swish-133            [-1, 480, 2, 2]               0\n",
      "AdaptiveAvgPool2d-134            [-1, 480, 1, 1]               0\n",
      "          Linear-135                 [-1, 1920]         923,520\n",
      "         Sigmoid-136                 [-1, 1920]               0\n",
      "           Swish-137                 [-1, 1920]               0\n",
      "          Linear-138                  [-1, 480]         922,080\n",
      "         Sigmoid-139                  [-1, 480]               0\n",
      "         SEBlock-140            [-1, 480, 1, 1]               0\n",
      "          Conv2d-141             [-1, 80, 2, 2]          38,400\n",
      "     BatchNorm2d-142             [-1, 80, 2, 2]             160\n",
      "          MBConv-143             [-1, 80, 2, 2]               0\n",
      "          Conv2d-144            [-1, 480, 2, 2]          38,400\n",
      "     BatchNorm2d-145            [-1, 480, 2, 2]             960\n",
      "         Sigmoid-146            [-1, 480, 2, 2]               0\n",
      "           Swish-147            [-1, 480, 2, 2]               0\n",
      "          Conv2d-148            [-1, 480, 2, 2]          12,000\n",
      "     BatchNorm2d-149            [-1, 480, 2, 2]             960\n",
      "         Sigmoid-150            [-1, 480, 2, 2]               0\n",
      "           Swish-151            [-1, 480, 2, 2]               0\n",
      "AdaptiveAvgPool2d-152            [-1, 480, 1, 1]               0\n",
      "          Linear-153                 [-1, 1920]         923,520\n",
      "         Sigmoid-154                 [-1, 1920]               0\n",
      "           Swish-155                 [-1, 1920]               0\n",
      "          Linear-156                  [-1, 480]         922,080\n",
      "         Sigmoid-157                  [-1, 480]               0\n",
      "         SEBlock-158            [-1, 480, 1, 1]               0\n",
      "          Conv2d-159            [-1, 112, 2, 2]          53,760\n",
      "     BatchNorm2d-160            [-1, 112, 2, 2]             224\n",
      "          MBConv-161            [-1, 112, 2, 2]               0\n",
      "          Conv2d-162            [-1, 672, 2, 2]          75,264\n",
      "     BatchNorm2d-163            [-1, 672, 2, 2]           1,344\n",
      "         Sigmoid-164            [-1, 672, 2, 2]               0\n",
      "           Swish-165            [-1, 672, 2, 2]               0\n",
      "          Conv2d-166            [-1, 672, 2, 2]          16,800\n",
      "     BatchNorm2d-167            [-1, 672, 2, 2]           1,344\n",
      "         Sigmoid-168            [-1, 672, 2, 2]               0\n",
      "           Swish-169            [-1, 672, 2, 2]               0\n",
      "AdaptiveAvgPool2d-170            [-1, 672, 1, 1]               0\n",
      "          Linear-171                 [-1, 2688]       1,809,024\n",
      "         Sigmoid-172                 [-1, 2688]               0\n",
      "           Swish-173                 [-1, 2688]               0\n",
      "          Linear-174                  [-1, 672]       1,807,008\n",
      "         Sigmoid-175                  [-1, 672]               0\n",
      "         SEBlock-176            [-1, 672, 1, 1]               0\n",
      "          Conv2d-177            [-1, 112, 2, 2]          75,264\n",
      "     BatchNorm2d-178            [-1, 112, 2, 2]             224\n",
      "          MBConv-179            [-1, 112, 2, 2]               0\n",
      "          Conv2d-180            [-1, 672, 2, 2]          75,264\n",
      "     BatchNorm2d-181            [-1, 672, 2, 2]           1,344\n",
      "         Sigmoid-182            [-1, 672, 2, 2]               0\n",
      "           Swish-183            [-1, 672, 2, 2]               0\n",
      "          Conv2d-184            [-1, 672, 2, 2]          16,800\n",
      "     BatchNorm2d-185            [-1, 672, 2, 2]           1,344\n",
      "         Sigmoid-186            [-1, 672, 2, 2]               0\n",
      "           Swish-187            [-1, 672, 2, 2]               0\n",
      "AdaptiveAvgPool2d-188            [-1, 672, 1, 1]               0\n",
      "          Linear-189                 [-1, 2688]       1,809,024\n",
      "         Sigmoid-190                 [-1, 2688]               0\n",
      "           Swish-191                 [-1, 2688]               0\n",
      "          Linear-192                  [-1, 672]       1,807,008\n",
      "         Sigmoid-193                  [-1, 672]               0\n",
      "         SEBlock-194            [-1, 672, 1, 1]               0\n",
      "          Conv2d-195            [-1, 112, 2, 2]          75,264\n",
      "     BatchNorm2d-196            [-1, 112, 2, 2]             224\n",
      "          MBConv-197            [-1, 112, 2, 2]               0\n",
      "          Conv2d-198            [-1, 672, 1, 1]          75,264\n",
      "     BatchNorm2d-199            [-1, 672, 1, 1]           1,344\n",
      "         Sigmoid-200            [-1, 672, 1, 1]               0\n",
      "           Swish-201            [-1, 672, 1, 1]               0\n",
      "          Conv2d-202            [-1, 672, 1, 1]          16,800\n",
      "     BatchNorm2d-203            [-1, 672, 1, 1]           1,344\n",
      "         Sigmoid-204            [-1, 672, 1, 1]               0\n",
      "           Swish-205            [-1, 672, 1, 1]               0\n",
      "AdaptiveAvgPool2d-206            [-1, 672, 1, 1]               0\n",
      "          Linear-207                 [-1, 2688]       1,809,024\n",
      "         Sigmoid-208                 [-1, 2688]               0\n",
      "           Swish-209                 [-1, 2688]               0\n",
      "          Linear-210                  [-1, 672]       1,807,008\n",
      "         Sigmoid-211                  [-1, 672]               0\n",
      "         SEBlock-212            [-1, 672, 1, 1]               0\n",
      "          Conv2d-213            [-1, 192, 1, 1]         129,024\n",
      "     BatchNorm2d-214            [-1, 192, 1, 1]             384\n",
      "          MBConv-215            [-1, 192, 1, 1]               0\n",
      "          Conv2d-216           [-1, 1152, 1, 1]         221,184\n",
      "     BatchNorm2d-217           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-218           [-1, 1152, 1, 1]               0\n",
      "           Swish-219           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-220           [-1, 1152, 1, 1]          28,800\n",
      "     BatchNorm2d-221           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-222           [-1, 1152, 1, 1]               0\n",
      "           Swish-223           [-1, 1152, 1, 1]               0\n",
      "AdaptiveAvgPool2d-224           [-1, 1152, 1, 1]               0\n",
      "          Linear-225                 [-1, 4608]       5,313,024\n",
      "         Sigmoid-226                 [-1, 4608]               0\n",
      "           Swish-227                 [-1, 4608]               0\n",
      "          Linear-228                 [-1, 1152]       5,309,568\n",
      "         Sigmoid-229                 [-1, 1152]               0\n",
      "         SEBlock-230           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-231            [-1, 192, 1, 1]         221,184\n",
      "     BatchNorm2d-232            [-1, 192, 1, 1]             384\n",
      "          MBConv-233            [-1, 192, 1, 1]               0\n",
      "          Conv2d-234           [-1, 1152, 1, 1]         221,184\n",
      "     BatchNorm2d-235           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-236           [-1, 1152, 1, 1]               0\n",
      "           Swish-237           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-238           [-1, 1152, 1, 1]          28,800\n",
      "     BatchNorm2d-239           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-240           [-1, 1152, 1, 1]               0\n",
      "           Swish-241           [-1, 1152, 1, 1]               0\n",
      "AdaptiveAvgPool2d-242           [-1, 1152, 1, 1]               0\n",
      "          Linear-243                 [-1, 4608]       5,313,024\n",
      "         Sigmoid-244                 [-1, 4608]               0\n",
      "           Swish-245                 [-1, 4608]               0\n",
      "          Linear-246                 [-1, 1152]       5,309,568\n",
      "         Sigmoid-247                 [-1, 1152]               0\n",
      "         SEBlock-248           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-249            [-1, 192, 1, 1]         221,184\n",
      "     BatchNorm2d-250            [-1, 192, 1, 1]             384\n",
      "          MBConv-251            [-1, 192, 1, 1]               0\n",
      "          Conv2d-252           [-1, 1152, 1, 1]         221,184\n",
      "     BatchNorm2d-253           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-254           [-1, 1152, 1, 1]               0\n",
      "           Swish-255           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-256           [-1, 1152, 1, 1]          28,800\n",
      "     BatchNorm2d-257           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-258           [-1, 1152, 1, 1]               0\n",
      "           Swish-259           [-1, 1152, 1, 1]               0\n",
      "AdaptiveAvgPool2d-260           [-1, 1152, 1, 1]               0\n",
      "          Linear-261                 [-1, 4608]       5,313,024\n",
      "         Sigmoid-262                 [-1, 4608]               0\n",
      "           Swish-263                 [-1, 4608]               0\n",
      "          Linear-264                 [-1, 1152]       5,309,568\n",
      "         Sigmoid-265                 [-1, 1152]               0\n",
      "         SEBlock-266           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-267            [-1, 192, 1, 1]         221,184\n",
      "     BatchNorm2d-268            [-1, 192, 1, 1]             384\n",
      "          MBConv-269            [-1, 192, 1, 1]               0\n",
      "          Conv2d-270           [-1, 1152, 1, 1]         221,184\n",
      "     BatchNorm2d-271           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-272           [-1, 1152, 1, 1]               0\n",
      "           Swish-273           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-274           [-1, 1152, 1, 1]          10,368\n",
      "     BatchNorm2d-275           [-1, 1152, 1, 1]           2,304\n",
      "         Sigmoid-276           [-1, 1152, 1, 1]               0\n",
      "           Swish-277           [-1, 1152, 1, 1]               0\n",
      "AdaptiveAvgPool2d-278           [-1, 1152, 1, 1]               0\n",
      "          Linear-279                 [-1, 4608]       5,313,024\n",
      "         Sigmoid-280                 [-1, 4608]               0\n",
      "           Swish-281                 [-1, 4608]               0\n",
      "          Linear-282                 [-1, 1152]       5,309,568\n",
      "         Sigmoid-283                 [-1, 1152]               0\n",
      "         SEBlock-284           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-285            [-1, 320, 1, 1]         368,640\n",
      "     BatchNorm2d-286            [-1, 320, 1, 1]             640\n",
      "          MBConv-287            [-1, 320, 1, 1]               0\n",
      "          Conv2d-288           [-1, 1280, 1, 1]         409,600\n",
      "     BatchNorm2d-289           [-1, 1280, 1, 1]           2,560\n",
      "         Sigmoid-290           [-1, 1280, 1, 1]               0\n",
      "           Swish-291           [-1, 1280, 1, 1]               0\n",
      "AdaptiveAvgPool2d-292           [-1, 1280, 1, 1]               0\n",
      "         Dropout-293                 [-1, 1280]               0\n",
      "          Linear-294                   [-1, 10]          12,810\n",
      "================================================================\n",
      "Total params: 63,598,858\n",
      "Trainable params: 63,598,858\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.84\n",
      "Params size (MB): 242.61\n",
      "Estimated Total Size (MB): 246.46\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = efficientnet_b0().to(device)\n",
    "summary(model, (3,28,28), device=device.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e1333cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "model.to(device)\n",
    "param = list(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1b961e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_acc(true, pred):\n",
    "    return sum(true == pred) / len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9441efc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|██▊                                                                                | 1/30 [00:22<10:59, 22.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss : 2.406503677368164, acc : 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|██████████████████████████████                                                    | 11/30 [04:08<07:12, 22.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, loss : 0.8348522186279297, acc : 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████████████████████████████████████▍                        | 21/30 [07:49<03:21, 22.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, loss : 1.3117749691009521, acc : 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [11:20<00:00, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, loss : 2.3525431156158447, acc : 0.375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for Epoch in tqdm(range(30)):\n",
    "    for batch, labels in mnist_loader:\n",
    "        batch = batch.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(batch)\n",
    "        loss = criterion(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        acc = compute_acc(labels.detach().cpu().numpy(), output.detach().cpu().numpy().argmax(-1))\n",
    "        \n",
    "    if Epoch % 10 == 0 or Epoch == 29:\n",
    "        print(f'Epoch {Epoch}, loss : {loss}, acc : {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abfd68d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./test/test_data.csv') \n",
    "test_file_dir = './test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b2cfd323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 157/157 [00:06<00:00, 24.34it/s]\n"
     ]
    }
   ],
   "source": [
    "test_mnist_dataset = MNIST(test_file_dir + test_df['file_name'])\n",
    "test_mnist_loader = DataLoader(test_mnist_dataset, batch_size = 32)\n",
    "preds = None\n",
    "\n",
    "for test_batch in tqdm(test_mnist_loader):\n",
    "    test_batch = test_batch.to(device)\n",
    "    output = model(test_batch)\n",
    "    \n",
    "    digit_pred = output.detach().cpu().numpy().argmax(-1)\n",
    "    if preds is None:\n",
    "        preds = digit_pred\n",
    "    else:\n",
    "        preds = np.concatenate([preds,digit_pred])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5c2210a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 8, 8, ..., 5, 7, 0], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc7ec7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv') # sample submission 불러오기\n",
    "\n",
    "submission['label'] = preds\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8140e445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
